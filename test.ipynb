{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n",
    "# Use AutoModelForX to solve task X with pretrained model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# Use AutoModel when customizing the architecture\n",
    "from transformers import AutoConfig, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bigscience/bloom-1b7'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# What is the diff with text generation ?\n",
    "# pipe = pipeline('conversational')\n",
    "\n",
    "pipe = pipeline(task='text-generation', model=model, tokenizer=tokenizer, max_new_tokens=30)\n",
    "\n",
    "out = pipe('Salut comment tu')\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_generator = pipeline('text-generation', model='bigscience/bloom-1b7')\n",
    "with torch.no_grad():\n",
    "    sentences = gpt2_generator(\"Hello, my dog is cute\", max_new_tokens=60, do_sample=True, \n",
    "                                top_k=100, top_p=0.92, temperature=0.9, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences\n",
    "print('sentence 1:')\n",
    "print(sentences[0]['generated_text'])\n",
    "print('\\n\\nSentence 2:')\n",
    "print(sentences[1]['generated_text'])\n",
    "print('\\n\\nSentence 3:')\n",
    "print(sentences[2]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader\n",
    "\n",
    "prompt = \"Hello, my dog is cute\"\n",
    "generation = loader.generate_text('bloom-1.7B', prompt, seed=0, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "generation[i] == sentences[i]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "inputs_for_gradio = [\"text\", \"text\", gr.Slider(50, 100), \"checkbox\", gr.Slider(0, 100), gr.Slider(0, 1),\n",
    "                      gr.Slider(0, 1), gr.Slider(1, 10), gr.Slider(0, 100)]\n",
    "\n",
    "demo = gr.Interface(fn=loader.generate_text, inputs=inputs_for_gradio, outputs=\"text\")\n",
    "\n",
    "demo.launch()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "gr.Interface.load(\"huggingface/bigscience/bloom-1b7\", \n",
    "    inputs=gr.Textbox(lines=5, label=\"Input Text\")  # customizes the input component\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 300\n",
    "\n",
    "def myfunc():\n",
    "  global x\n",
    "  x = 200\n",
    "\n",
    "myfunc()\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with gr.Blocks() as demo:\n",
    "    table = gr.Radio(['fof', 'foo', 'fnw√©'])\n",
    "    textbox = gr.Textbox(\"Hello World!\")\n",
    "\n",
    "    statement = gr.Textbox()\n",
    "\n",
    "    # def on_select(evt: gr.SelectData):  # SelectData is a subclass of EventData\n",
    "        # return f\"You selected {evt.value} at {evt.index} from {evt.target}\"\n",
    "\n",
    "    def test(input):\n",
    "        return f'{input}'\n",
    "\n",
    "    # table.select(on_select, None, statement)\n",
    "    table.input(test, table, statement)\n",
    "    # textbox.select(on_select, None, statement)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
